Search.setIndex({docnames:["conclusions/future_perspectives","fundamentals/acoustics","fundamentals/artificial_neural_networks","fundamentals/cross_validation","fundamentals/frequency_spectrum","fundamentals/multiple_layer_feedforward_networks","fundamentals/performance_measurement_metrics","fundamentals/recurring_networks","fundamentals/related_works","fundamentals/sound_descriptors","fundamentals/sound_source_rating","fundamentals/sound_source_separation","fundamentals/training","fundamentals/wrap","index","introduction/contextualization","introduction/presentation_of_the_manuscript","introduction/problem_definition","introduction/project_objectives","methodology/classification_based_on_descriptors","methodology/elman_network","methodology/multilayer_perceptron","methodology/samples","results/classification_based_on_descriptors","results/elman_network","results/multilayer_perceptron","results/samples"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,sphinx:56},filenames:["conclusions/future_perspectives.md","fundamentals/acoustics.md","fundamentals/artificial_neural_networks.md","fundamentals/cross_validation.md","fundamentals/frequency_spectrum.md","fundamentals/multiple_layer_feedforward_networks.md","fundamentals/performance_measurement_metrics.md","fundamentals/recurring_networks.md","fundamentals/related_works.md","fundamentals/sound_descriptors.md","fundamentals/sound_source_rating.md","fundamentals/sound_source_separation.md","fundamentals/training.md","fundamentals/wrap.md","index.md","introduction/contextualization.md","introduction/presentation_of_the_manuscript.md","introduction/problem_definition.md","introduction/project_objectives.md","methodology/classification_based_on_descriptors.md","methodology/elman_network.md","methodology/multilayer_perceptron.md","methodology/samples.md","results/classification_based_on_descriptors.md","results/elman_network.md","results/multilayer_perceptron.md","results/samples.md"],objects:{},objnames:{},objtypes:{},terms:{"2021":14,"bras\u00edlia":14,"monof\u00f4nica":14,"separa\u00e7\u00e3o":14,"voc\u00ea":14,address:14,author:14,bauchspiess:14,bibtex:14,brasil:14,daniel:14,entrada:[],font:14,institut:14,para:14,pode:14,seguint:14,sonora:14,techreport:14,titl:14,universidad:14,utilizar:14,year:14},titles:["Perspectivas Futuras","Ac\u00fastica","Redes Neurais Artificiais","Valida\u00e7\u00e3o Cruzada","Espectro de Frequ\u00eancias","Redes Multiple-Layer Feedforward","M\u00e9tricas de Avalia\u00e7\u00e3o de Desempenho","Redes Recorrentes","Trabalhos Relacionados","Descritores Sonoros","Classifica\u00e7\u00e3o de Fonte Sonora","Separa\u00e7\u00e3o de Fonte Sonora","Treinamento","Envolt\u00f3ria","Como referenciar este trabalho:","Contextualiza\u00e7\u00e3o","Apresenta\u00e7\u00e3o do Manuscrito","Defini\u00e7\u00e3o do Problema","Objetivos do Projeto","Classifica\u00e7\u00e3o Baseada em Descritores","Rede De Elman","Multilayer Perceptron","Amostras","Classifica\u00e7\u00e3o Baseada em Descritores","Rede De Elman","Multilayer Perceptron","Amostras"],titleterms:{"ac\u00fastica":1,"apresenta\u00e7\u00e3o":16,"avalia\u00e7\u00e3o":6,"classifica\u00e7\u00e3o":[10,19,23],"contextualiza\u00e7\u00e3o":15,"defini\u00e7\u00e3o":17,"envolt\u00f3ria":13,"frequ\u00eancia":4,"m\u00e9trica":6,"monof\u00f4nica":[],"p\u00e1gina":[],"separa\u00e7\u00e3o":11,"separara\u00e7\u00e3o":[],"valida\u00e7\u00e3o":3,amostra:[22,26],artificiai:2,baseada:[19,23],como:14,cruzada:3,descritor:[9,19,23],desempenho:6,document:[],elman:[20,24],espectro:4,est:14,feedforward:5,font:[10,11],futura:0,inici:[],layer:5,manuscrito:16,multilay:[21,25],multipl:5,neurai:2,objetivo:18,perceptron:[21,25],perspectiva:0,problema:17,projeto:18,recorrent:7,rede:[2,5,7,20,24],referenciar:14,relacionado:8,sonora:[10,11],sonoro:9,trabalho:[8,14],treinamento:12}})