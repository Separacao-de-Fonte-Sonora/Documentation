Search.setIndex({docnames:["README","conclusions/future_perspectives","fundamentals/acoustics","fundamentals/artificial_neural_networks","fundamentals/cross_validation","fundamentals/frequency_spectrum","fundamentals/multiple_layer_feedforward_networks","fundamentals/performance_measurement_metrics","fundamentals/recurring_networks","fundamentals/related_works","fundamentals/sound_descriptors","fundamentals/sound_source_rating","fundamentals/sound_source_separation","fundamentals/training","fundamentals/wrap","introduction/contextualization","introduction/presentation_of_the_manuscript","introduction/problem_definition","introduction/project_objectives","methodology/classification_based_on_descriptors","methodology/elman_network","methodology/multilayer_perceptron","methodology/samples","results/classification_based_on_descriptors","results/elman_network","results/multilayer_perceptron","results/samples"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,sphinx:56},filenames:["README.md","conclusions/future_perspectives.md","fundamentals/acoustics.md","fundamentals/artificial_neural_networks.md","fundamentals/cross_validation.md","fundamentals/frequency_spectrum.md","fundamentals/multiple_layer_feedforward_networks.md","fundamentals/performance_measurement_metrics.md","fundamentals/recurring_networks.md","fundamentals/related_works.md","fundamentals/sound_descriptors.md","fundamentals/sound_source_rating.md","fundamentals/sound_source_separation.md","fundamentals/training.md","fundamentals/wrap.md","introduction/contextualization.md","introduction/presentation_of_the_manuscript.md","introduction/problem_definition.md","introduction/project_objectives.md","methodology/classification_based_on_descriptors.md","methodology/elman_network.md","methodology/multilayer_perceptron.md","methodology/samples.md","results/classification_based_on_descriptors.md","results/elman_network.md","results/multilayer_perceptron.md","results/samples.md"],objects:{},objnames:{},objtypes:{},terms:{},titles:["Documentation","Perspectivas Futuras","Ac\u00fastica","Redes Neurais Artificiais","Valida\u00e7\u00e3o Cruzada","Espectro de Frequ\u00eancias","Redes Multiple-Layer Feedforward","M\u00e9tricas de Avalia\u00e7\u00e3o de Desempenho","Redes Recorrentes","Trabalhos Relacionados","Descritores Sonoros","Classifica\u00e7\u00e3o de Fonte Sonora","Separa\u00e7\u00e3o de Fonte Sonora","Treinamento","Envolt\u00f3ria","Contextualiza\u00e7\u00e3o","Apresenta\u00e7\u00e3o do Manuscrito","Defini\u00e7\u00e3o do Problema","Objetivos do Projeto","Classifica\u00e7\u00e3o Baseada em Descritores","Rede De Elman","Multilayer Perceptron","Amostras","Classifica\u00e7\u00e3o Baseada em Descritores","Rede De Elman","Multilayer Perceptron","Amostras"],titleterms:{"ac\u00fastica":2,"apresenta\u00e7\u00e3o":16,"avalia\u00e7\u00e3o":7,"classifica\u00e7\u00e3o":[11,19,23],"contextualiza\u00e7\u00e3o":15,"defini\u00e7\u00e3o":17,"envolt\u00f3ria":14,"frequ\u00eancia":5,"m\u00e9trica":7,"separa\u00e7\u00e3o":12,"valida\u00e7\u00e3o":4,amostra:[22,26],artificiai:3,baseada:[19,23],cruzada:4,descritor:[10,19,23],desempenho:7,document:0,elman:[20,24],espectro:5,feedforward:6,font:[11,12],futura:1,layer:6,manuscrito:16,multilay:[21,25],multipl:6,neurai:3,objetivo:18,perceptron:[21,25],perspectiva:1,problema:17,projeto:18,recorrent:8,rede:[3,6,8,20,24],relacionado:9,sonora:[11,12],sonoro:10,trabalho:9,treinamento:13}})